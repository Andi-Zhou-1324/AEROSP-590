\documentclass[a4paper]{article}
%% Language and font encodings
\usepackage{graphicx, cite, verbatim, color, amsmath, amssymb}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocodex}

\setlength{\abovecaptionskip}{2pt}
\setlength{\belowcaptionskip}{2pt}

% \usepackage{algcompatible}
\usepackage{subcaption}
\usepackage{bm}
\usepackage[compact]{titlesec}


%\setlength{\headheight}{0in}
\setlength{\headsep}{0.3in}
\setlength{\topmargin}{-0.5in}
\setlength{\textheight}{8.8in}
\setlength{\textwidth}{7in}
\setlength{\oddsidemargin}{-.35in}
\setlength{\evensidemargin}{-.35in}
\setlength{\unitlength}{1in}


% useful shortcuts/macros
\newcommand{\be}{\begin{eqnarray}}
\newcommand{\ee}{\end{eqnarray}}
\newcommand{\ben}{\begin{eqnarray*}}
\newcommand{\een}{\end{eqnarray*}}
\newcommand{\mbf}{\mathbf}
\newcommand{\mbfv}[1]{\vec{\mathbf{#1}}}
\newcommand{\sbf}[1]{\boldsymbol{#1}}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\pp}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dd}[2]{\frac{d #1}{d #2}}

% \newcommand{\algmargin}{\the\ALG}
% \makeatother
% \newlength{\whilewidth}
%\settowidth{\whilewidth}{\algorithmicwhile\ }
%\algdef{SE}[parWHILE]{parWhile}{EndparWhile}[1]
%  {\parbox[t]{\dimexpr\linewidth-\algmargin}{%
%     \hangindent\whilewidth\strut\algorithmicwhile\ #1\ \algorithmicdo\strut}}{\algorithmicend\ \algorithmicwhile}%
%\algnewcommand{\State }[1]{\State%
%  \parbox[t]{\dimexpr\linewidth-\algmargin}{\strut #1\strut}}
  
% abstract formatting
\RequirePackage[style]{abstract}
\renewcommand{\abstitlestyle}[1]{}
\renewcommand{\abstracttextfont}{\bfseries\normalsize}
\setlength{\absleftindent}{0in}
\setlength{\absrightindent}{0in}

% caption formatting
\RequirePackage[tableposition=top]{caption}
\captionsetup*{font=bf}

% code listing formatting
\definecolor{commentgreen}{RGB}{14,120,0}
\lstset{
  numbers=none, 
  basicstyle=\scriptsize, 
  commentstyle=\color{commentgreen},
  keywordstyle=\bf\color{blue},
  language=python, 
  frame=shadowbox,
  rulesepcolor=\color{black},
  flexiblecolumns=true,
  extendedchars=false,
  showstringspaces=false,
  keepspaces=true
}

% packed itemize
\newenvironment{itemizePacked}{
\begin{itemize}
  \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

% packed enumerate
\newenvironment{enumeratePacked}{
\begin{enumerate}
  \setlength{\itemsep}{-1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{enumerate}}


% no indent
\setlength{\parindent}{0pt}

% column separation
\setlength{\columnsep}{3ex}

% header
\fancyhead[L]{
\large \sc
Entropy Stability
}
\renewcommand{\headrulewidth}{1pt}
\pagestyle{fancy}

% section spacing
\titlespacing{\section}{0pt}{12pt}{4pt}
\titlespacing{\subsection}{0pt}{8pt}{2pt}

%section numbering for equations 
\numberwithin{equation}{section}
\makeatletter
\@addtoreset{equation}{section}
\makeatother
\title{AEROSP 590: Entropy Stability}
\author{Andi Zhou}
\begin{document}
\maketitle

\section{Entropy Condition - Origin and Formulation}
In this section we explain the entropy condition, and explain why this would be necessary in solving Hyperbolic Partial Differential Equations. To explain the neccesity of entropy condition, we first start but discussing a typical conservation law.

\begin{equation} \label{singleConservationLaw}
    \partial_t u^j + \partial_x f^j = 0
\end{equation}
where $f$ is a non-linear function of $U$, where:
\begin{equation}
    \frac{df}{du} = a(u)
\end{equation}
Using chain rule, we could write Equation \ref{singleConservationLaw} as:
\begin{equation}\label{singleConservationLaw_wavespeed}
    u_t + a(u)u_x = 0
\end{equation}
If $u$ is constant along a characteristic trajectory, we also know that $a$ will be constant as well. $u$ would propagate along space in speed $a$. Therefore, we also define $a$ as the signal speed. The trajectories of $u$ would be defined as a characteristics. Equation \ref{singleConservationLaw} is known as the strong (differential) form of the PDE, where a solution to this equation would need to satisfy the differential operators at all points in space and time. A solution that matches the strong form is known as the a strong solution. However, the differential form could not admit discontinuities. Consider, for example, the inviscid Burger's equation:
\begin{equation}
    \partial_t u + u \partial_x u = 0
\end{equation}
Where now the wavespeed depends upon the state $a(u) = u$. If we draw the characteristic curve of the Burger's equation subject to a Gaussian initial condition, we would find that the characteristic lines may eventually intersect at one point (Figure \ref{BurgerEquationFigure}). 
\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{fig/BurgersCharacteristic.png}
    \caption{Example characteristic curve of Burger's equation}
    \label{BurgerEquationFigure}
\end{figure}
The above figure is subjected to the following initial condition:
\begin{equation}
    u(x,0) = 
    \begin{cases}
        \sin^2 (\pi x) & 0 \leq x \leq 1 \\
        0 & 1 \leq x \leq 2
    \end{cases}
\end{equation}
We see that due to the difference the state, the slope ($1/a$) varies across the domain which causes characteristic lines to intersect each other. At the point of intersection, then, there exists two states, which represents a discontinuity. This is impossible when considering the strong form (Equation \ref{singleConservationLaw}). Then, we require a different formulation of the above conservation law.
\subsection{The Weak Form of Conservation Law}
We now consider the weak form:

\begin{equation}\label{eq:integralConservationLaw}
    \int_{0}^{\infty} \int_{-\infty}^{\infty} \left[w_t u + w_x f(u) \right] dx dt + \int_{\infty}^\infty w(x,0) \phi(x) dx = 0
\end{equation}
where $w$ is any smooth test function with compact support (non-zero only within the specified element). The general idea of weak solution is that we could rewrite the derivatives of $u$ as derivatives of compact test function $w$. From this, we basically eliminated the need for solution to be continuous. However, for hyperbolic systems (which we are interested in), the notion of weak solution \textbf{does not} guarantee uniqueness. Therefore, we need some sort of criterions to select a solution that is \textit{physical}. We then have the \textbf{entropy} condition. 

In order to better study the region of discontinuity, we turn to Equation \ref{singleConservationLaw} and add a term of dissipation at the end:
\begin{equation} \label{eq:artificial_viscosity}
   u_t + f_x = \epsilon u_{xx}
\end{equation}
The term on the right hand side is also known as artificial viscosity. This allows us to identify relevant solutions as limits of solutions of equations with some dissipation. As $\epsilon \rightarrow 0$, the solution would tend towards Equation \ref{singleConservationLaw} in a \textit{weak} sense. 

Now, we consider a convex function $U(u)$ that is a function $u$ and its corresponding convex flux $F(u)$. We assume that these convex function also satisfy a separate form of conservation law:
\begin{equation}
    U_t + F_x = 0
\end{equation}

Again from [], we understand that if the convex function $U$ satisfies a conservation law then multiplying the system by $U_j$, would put the system into \textit{symmetric hyperbolic form}.

We use the above theorem, and we multiply Equation \ref{eq:artificial_viscosity} by $U_j$, and we arrive at the following:
\begin{equation}
    \partial_t U + \partial_x F = \epsilon \sum U_j u^j_{xx}
\end{equation}

Lax introduced the following identity:
\begin{equation}
    \partial_x^2 U = \sum U_j \partial_x^2 u^j + \sum U_{jk} \partial_x u^j \partial_x u^k
\end{equation}
From above, we could deduce that:
\begin{equation}
    \partial_x^2 U \geq \sum U_j \partial_x^2 u^j
\end{equation}
Since we know that $\epsilon > 0$ in Equation \ref{eq:artificial_viscosity}, we could use the above equation estimate the right side:
\begin{equation}
    \partial_t U + \partial_x F \leq \epsilon \partial_x^2 F
\end{equation}
Take $\epsilon \rightarrow 0$, we then recover the entropy condition:
\begin{equation}
    \partial_t U + \partial_x F \leq 0
\end{equation}

We note that, if $u$ is a piecewise continous solution to Equation \ref{singleConservationLaw}, we could arrive at the following assuming we are at a point of discontinuity:
\begin{equation}
    s \left[U\right] - \left[F\right] \leq 0
\end{equation}
where $s$ is the speed of the discontinuity while $\left[\cdot\right]$ denotes jump in the respective quantity across the discontinuity. The above relation is analogous to the Rankine-Hugoniot jump relation:
\begin{equation}
    s \left[u^j\right] - \left[f^j\right] = 0
\end{equation}
We could actually rewrite the entropy condition as follow:
\begin{equation}
    \frac{f(u) - f(u_L)}{u-u_L} \geq S \geq \frac{f(u) - f(u_R)}{u-u_R}
\end{equation}
This is known by Oleinik[] as \textit{Condition E}. If we use the Rankine-Hugoniot jump relation:
\begin{equation}
    f(u_R) - f(u_L) = S(u_R - u_L)
\end{equation}
we also arrive at the \textit{Lax entropy condition} []:
\begin{equation}
    a(u_l) > S > a(u_r)
\end{equation}
%%Commented it out just cuz
\begin{comment}
It is rather difficult to trace when the notion of entropy condition was first introduced. Earliest written work that could be traced on this subjects were done by P. Lax [citation] and O. Oleinik [citation]. Both authors have mentioned the idea of \textit{entropy conditions} repeatedly in their text. 
\end{comment}


%----------------------------------------
\section{Entropy Satisfied Schemes}
Several fluxes satisfy the above entropy condition. We understood from Lax [] that any monotone scheme satisfy the entropy condition. In this section we specifically focus on first order scheme, and list two of these fluxes below.

\subsection{Lax-Friedrich's Scheme}
The Lax-Friedrich scheme, under a specific CFL number, satisfies the entropy condition. The scheme is introduced by Lax in 1954 as a method of discretizing the first order hyperbolic equation without violating the entropy condition introduced in the above section. We introduce the general scheme below, and demonstrate that it is actually a FTCS (forward in time, centered in space) scheme with the temporal derivative replaced by a spatial average of the neighboring points. 
The general Lax-Friedrich discretization is as follow:
\begin{equation}
    \begin{split}
        u_t &= \frac{1}{\Delta t}\left( u^{n+1}_j - \frac{u^n_{j-1} + u^n_{j+1}}{2} \right)  \\
        f_x &= \frac{1}{2\Delta x}\left(f(u^n_{j+1}) - f(u^n_{j-1})\right)
    \end{split}
\end{equation}
Combined together, we obtain the Lax-Friedrich scheme:
\begin{equation}
    \begin{split}
        &\frac{1}{\Delta t}\left( u^{n+1}_j - \frac{u^n_{j-1} + u^n_{j+1}}{2} \right) + \frac{1}{2\Delta x}\left(f(u^n_{j+1}) - f(u^n_{j-1})\right) = 0 \\
        &u_j^{n+1} = \frac{1}{2}(u_{i+1}^n + u_{i-1}^n) - \frac{\Delta t}{2\Delta x}\left(f(u^n_{j+1}) - f(u^n_{j-1})\right)
    \end{split}
\end{equation}
We note that the above scheme is essentialy FTCS:
\begin{equation}
    u_j^{n+1} = \underbrace{\frac{1}{2}(u_{i+1}^n + u_{i-1}^n)}_{\text{Temporal Derivative}} - \underbrace{\frac{\Delta t}{2\Delta x}\left(f(u^n_{j+1}) - f(u^n_{j-1})\right)}_{\text{Spatial derivative (Centered in Space)}}
\end{equation}
According to Lax[], the Lax-Friedrich scheme satisfies the entropy condition under a suitable choice of the $\lambda = \frac{\Delta t}{\Delta x}$.

The Lax-Friedrich scheme satisfies the entropy condition as long as the $\lambda = \frac{\Delta t}{\Delta x}$ satisfies the following criterion:
\begin{equation}
    c\lambda \leq \sqrt{1+m/M-1}
\end{equation}
where $M$ and $m$ are the minimum and maximum eigenvalues of the entropy function Jacobian $\frac{\partial^2}{\partial^2 u}U$ and $c$ denotes the norm of the entropy function derivative $\frac{\partial}{\partial u} U$. The complete proof is presented in section 1 of []. The above inequality could also be transformed in terms of the Courant-Friedrich-Lewy (CFL) number, where the scheme is entropy stable if:
\begin{equation}
    CFL = \frac{a \Delta t}{\Delta x} \leq 1
\end{equation}
where for a $CFL \leq 1$, the Lax-Friedrich scheme is monotone, which satisfies the entropy condition according to Lax [].


%---------------------------------------------------------
\subsection{Engquist-Osher Scheme}
The E-O scheme, or Engquist and Osher scheme could be considered as a modified version of the Cole-Murman scheme used for small disturbance equation of transonic flow.  Engquist and Osher introduced this scheme in a paper publised in 1980 [] and then later generalized this scheme for general hyperbolic systems of conservation laws []. We discuss the formulation of this particular scheme here along with its relevant mathematical proofs.
Consider a non-linear scalar conservation law in 1D:
\begin{equation} 
    w_t + f(w)_x = 0,\\ w(x,t=0) = \Phi(x). \ =\infty < x< \infty
\end{equation}
The solution is approximated by a mesh function $w_j^n$ on the mesh ${(x_J,t^n)}$ with $x_j = k \Delta x, t^n = n \Delta t, j = 0, \pm 1,...,n=0,1,...$. In explicit form, the finite difference approximation is defined as:
\begin{enumerate}
    \item 
\begin{equation} \label{eq:E-O Conservation Law}
    \begin{split}
        w_j^{n+1} &= w_j^n - \frac{\Delta t}{\Delta x}\left(\Delta_{+} f_{-} (w_j^n) + \Delta_{-} f_{+} (w_j^n) \right) \\
        w_j^0 &= \Phi(x_j), j = 0, \pm 1, \pm 2\\
    \end{split}
\end{equation}
    \item \label{eq:E-O_CFL}
        \begin{equation}
            \frac{\Delta t}{\Delta x} \text{sup} |f'| < 1
        \end{equation}

\end{enumerate}
We denote here as a reminder that Part 1 is the fully-discrete version of Equation \ref{eq:E-O Conservation Law} written is a per cell. We specify here as well the following notations:
\begin{equation}
    \begin{split}
        \Delta_{\pm} w_j &= \pm (w_{j\pm 1} - w_j)\\
        D_{\pm} w_j &= \frac{1}{\Delta x} \Delta_{\pm} w_j\\
    \end{split} 
\end{equation}
The auxiliary functions $f_+$ and $f_-$ are:
\begin{equation}
    \begin{split}
        f_+ (w) &= \int_0^w \mathcal{X} (w) f'(w) dw\\
        f_- (w) &= \int_0^w (1 - \mathcal{X}(w)) f'(w)dw\\
    \end{split}
\end{equation}
When $f$ is convex, the definitions then reduce to:
\begin{equation}
    \begin{split}
        f_+ (w) &= f(\mathrm{max}(w,\bar{w}))\\
        f_- (w) &= f(\mathrm{min}(w,\bar{w})) \\
    \end{split}
\end{equation}

where $\bar{u}$ is the stagnation or sonic point for which $f'(\bar{u}) = 0$. We make a note that when the sign is positive, Equation \ref{eq:E-O Conservation Law} becomes the \textit{upwind} algorithm. This is also known as \textit{flux decomposition}, where we separated the original upwinding flux into essentially a decreasing and increasing components. Decomposing this flux into different components provides us with a different perspective when looking at states near shock points.

When we consider a hyperbolic PDE with convex flux, we arrive at the following:
\begin{equation}
    \begin{split}
        f^+ (w) &= 
        \begin{cases}
            f(w), & w \geq \bar{w}\\
            f(\bar{w}), & w \leq \bar{w}\\
        \end{cases}\\
        f^-(w) &= 
        \begin{cases}
            f(w), & w \leq \bar{w} \\
            f(\bar{w}), & w \geq \bar{w}\\
        \end{cases}\\
    \end{split}
\end{equation}
If we have Burger's equation, then the flux becomes: $f(u) = \frac{u^2}{2}$:

\begin{equation}
    \begin{split}
        f^+ (u) &= 
        \begin{cases}
            \frac{u^2}{2}, & u \geq u^*\\
            0, & u \leq u^*\\
        \end{cases}\\
        f^-(u) &= 
        \begin{cases}
            \frac{u^2}{2}, & u \leq u^* \\
            0, & u \geq u^*\\
        \end{cases}\\
    \end{split}
\end{equation}
If we consider an arbitary, following the notation from Equation \ref{eq:E-O Conservation Law}, we have, 
\begin{equation}
    \Delta_- f_+ = f^+(w_j) + f^-({w_{j+1}})
\end{equation}
The Engquist and Osher scheme demonstrated computational advantages over all previous schemes including Godunov's and Cole-Murman, especially for implicit calculations where a much large time steps could be taken for E-O. It also elimnates the non-physical expansion shocks (satisfies the entropy condition) that plagues the C-M and Roe's method, and also possesses \textit{smoother} flux functions than that of Godunov's.

The E-O scheme is \textit{monotone} if the CFL condition (Equation \ref{eq:E-O_CFL}) is valid[]. Lax proved in [] that monotone schemes always satisfy the entropy condition and converge to a physically relevant solution. From this theorem, we then know that E-O scheme is entropy stable if the CFL condition if Equation \ref{eq:E-O_CFL} is satisfied.

%----------------------------------------------------------------------
\section{The Roe Scheme}
Professor Philip Roe first introduced the Roe scheme in 1980 in his paper \textit{Approximate Riemann Solvers, Parameter Vectors, and Difference Scheme} []. In his paper, Roe argued that an exact solution to the Riemann problem may not be necessary and we could construct an \textit{approximate} solutions which are the \textit{exact} solutions to an approximate problem. This is the motive behind the \textit{Roe's Average}. 
\subsection{Roe's Average}
Consider again the one-dimensional linear advection equation:
\begin{equation}
    u_t + au_x = 0
\end{equation}
where we construct an approximate version:
\begin{equation}
    \mathbf{u}_t + \tilde{A}\mathbf{u}_x = 0
\end{equation}
where $\tilde{A}$ is to be chosen such that it satisfies the \textit{local} conditions, i.e based on $A_L$ and $A_R$. The intuitive candidates are, of course:
\begin{equation}
    \begin{split}
        \tilde{A} &= \frac{1}{2}(A_L + A_R)\\
        \tilde{A} &= A(\frac{1}{2}(\mathbf{u}_L + \mathbf{u}_R))\\
    \end{split}
\end{equation}
However, Roe listed out the following properties that the matrix $\tilde{A}$ has to satisfy:
\begin{enumerate}
    \item Linear mapping from the vector space $\mathbf{u}$ to the vector space $\mathbf{F}$
    \item As $\mathbf{u}_L \rightarrow \mathbf{u}_R \rightarrow \mathbf{u}, \tilde{A}(\mathbf{u}_L,\mathbf{u}_R) \rightarrow A(\mathbf{u})$ where $A = \frac{\partial \mathbf.
    F}{\partial \mathbf{u}}$. In words, the approximate Jacobian $\tilde{A}$ must match with the exact Jacobian $A$ as $\mathbf{u}_L$ and $\mathbf{u}_R$ approaches $\mathbf{u}$
    \item For any $\mathbf{u}_L, \mathbf{u}_R, \tilde{A}(\mathbf{u}_L, \mathbf{u}_R)\times (\mathbf{u}_L - \mathbf{u}_R) = \mathbf{F}_L - \mathbf{F}_R$. In words, conservation must be satisfied.
    \item The eignvectors of $\tilde{A}$ are linearly independent, which means thats the PDE has to be \textit{hyperbolic}.

\end{enumerate}
The above conditions are named Property U, as they are intended to possess uniform validity across discontinuities. In addition, matrix $\tilde{A}$ is sometimes called \textit{Roes's matrix}. It is to be noted that none of the suggestions for $\tilde{A}$ above satisfies the third property. 

We then follow that the matrix $\tilde{A}$ could be constructed from mean value theorems which would arrive at the following:
\begin{equation}
    \tilde{A} = \int_0^1 A(\theta) d \theta
\end{equation}
where $\theta$ is a parameter that vary linearly between 0 and 1 along a straight path connecting each state. By choosing a suitable integration path, candidates for $A$ that is closed and cheap to compute could be found. We could then have the following formula based on $\tilde{A}$:
\begin{equation} \label{Roe's Integral}
    F_j(\mathbf{u}_L) - F_j(\mathbf{u}_R) = \sum_i \tilde{a}_{ij} \left[(u_i)_L - (u_i)_R\right]
\end{equation} 
where $a_ij$ is the matrix entries into $\tilde{A}$. The $\tilde{a}_{ij}$ satisfies the first amd third conditions of Property U.

However, the primary disadvantage of the above construction lies in that the matrix is far from unique, and the resulting formulae for eigenvalues and eigenvectors are sometimes quite cumbersome. For Euler's equation, however, the above formulae simplifies greatly due to Euler's homogenity characteristic. 

\subsection{Roe's Scheme for Euler's Equation}
For Euler's compressible flow equation (or polytropic ideal gases), Roe introduced a change of variable:
\begin{equation}
    \mathbf{w} = \rho^{1/2}(1,u,v,w,H)^T
\end{equation}
which allow us to easily integrate and satisfy the Equation \ref{Roe's Integral}. We introduce two equations:
\begin{equation}
    \begin{split}
        \left(\mathbf{u}_L - \mathbf{u}_R\right) &= \tilde{B}(\mathbf{w}_L - \mathbf{w}_R)\\
        \left(\mathbf{F}_L - \mathbf{F}_R\right) &= \tilde{C}(\mathbf{w}_L - \mathbf{w}_R)\\
    \end{split}
\end{equation}
where the first equation provides a link for $\mathbf{w}$ in terms of $\mathbf{u}$. Then, through the new change of variables conducted we could write the following $\tilde{B}$ and $\tilde{C}$ matrix:
\begin{equation}
    \begin{split}
        \tilde{B} &=
        \begin{pmatrix}
            2 \bar{\mathrm{w}}_1 & 0 & 0 & 0 & 0\\
            \bar{\mathrm{w}}_2 & \bar{\mathrm{w}}_1 & 0 & 0 & 0\\
            \bar{\mathrm{w}}_3 & 0 & \bar{\mathrm{w}}_1 & 0 & 0\\
            \bar{\mathrm{w}}_4 & 0 & 0 &\bar{\mathrm{w}}_1 & 0 \\
           \frac{\bar{\mathrm{w}}_5}{\gamma} & \frac{\gamma - 1}{\gamma}\bar{\mathrm{w}}_2 & \frac{\gamma - 1}{\gamma }\bar{\mathrm{w}}_3 & \frac{\gamma - 1}{\gamma} \bar{\mathrm{w}}_4 & \frac{\bar{\mathrm{w}}_1}{\gamma}
        \end{pmatrix} \\
        \tilde{C} &= 
        \begin{pmatrix}
            \bar{\mathrm{w}}_2 & \bar{\mathrm{w}}_1 & 0 & 0 & 0\\
            \frac{\gamma - 1}{\gamma}\bar{\mathrm{w}}_5 & \frac{\gamma - 1}{\gamma}\bar{\mathrm{w}}_2 & -\frac{\gamma - 1}{\gamma}\bar{\mathrm{w}}_3 & -\frac{\gamma - 1}{\gamma} \bar{\mathrm{w}}_4 & \frac{\gamma - 1}{\gamma} \bar{\mathrm{w}}_1\\
            0 & \bar{\mathrm{w}}_3 & \bar{\mathrm{w}}_2 & 0 & 0\\
            0 & \bar{\mathrm{w}}_4 & 0 & \bar{\mathrm{w}}_2 & 0\\
            0 & \bar{\mathrm{w}}_5 & 0 & 0 & \bar{\mathrm{w}}_2\\
        \end{pmatrix}
    \end{split}
\end{equation}
The $\bar{\cdot}$ indicates the arithmatic average of the selected quanitites. We then obtain $\tilde{A}$ via:
\begin{equation}
    \tilde{A} = \tilde{C}\tilde{B}^{-1}
\end{equation}
In the process of providing an analytical equation for both the eigenvalues and eigenvectors, Roe then introduced a different form of averaging for ease of convention:
\begin{equation}
    u = \frac{\rho^{1/2}_L u_L + \rho^{1/2}_R u_R}{\rho_L^{1/2} + \rho_R^{1/2}} = \frac{\bar{\mathrm{w}}_2}{\bar{\mathrm{w}}_1}
\end{equation}
We could also follow similar convention for:
\begin{equation}
    v = \frac{\bar{\mathrm{w}}_3}{\bar{\mathrm{w}}_1}, \ w = \frac{\bar{\mathrm{w}}_4}{\bar{\mathrm{w}}_1}, \ H = \frac{\bar{\mathrm{w}}_5}{\bar{\mathrm{w}}_1}
\end{equation}
The above relations are known as the Roe average, in which Roe derived on obtaining a solution to the linearized Riemann problem. It is to be noted that $\tilde{A}$ is equal to the original matrix $A$ when evaluated with the Roe averaged states above. 
%%-----------------------------------------------------------------------------------
\section{Tadmor's Entropy Stability Criterion}
Eitan Tadmor, in his paper written in 1987, introduced a new, general, criterion capable of evaluating entropy conservation of different numerical fluxes. This section summarizes his paper and the two main theorems that he proposed:
\begin{enumerate}
    \item Entropy conservation by means of comparison
    \item Three-point conservative schemes are entropy stable if and only if they contain \textit{more} viscosity than their entropy conservative equivalent
\end{enumerate}
We focus on the derivation and discussion for the first theorem and briefly states the second.

%%-----------------------------------------------------------------------------------
\subsection{Tadmor's Entropy Stability Criterion}
We again consider a one-dimensional conservation law:
\begin{equation}
    \frac{\partial}{\partial t} \mathbf{u} + \frac{\partial}{\partial x}\left[\mathbf{f(u)}\right] = 0
\end{equation}
and we introduce the entropy function $U(u)$, a \textit{convex} function of $u$ along with the entropy flux $F(u)$, which is also a convex function of $u$. We recall the entropy condition:
\begin{equation}\label{eq:EntrpyInequality}
    \frac{\partial V}{\partial t} + \frac{\partial G}{\partial x} \leq 0
\end{equation}
where:
\begin{equation}
    V(\mathbf{v}) = U(\mathbf{u(v)}), \ G(\mathbf{v}) = F(\mathbf{u(v)})
\end{equation}
We also introduce the entropy variable:
\begin{equation}
    \mathbf{v} = \mathbf{v(u)} = \frac{\partial \mathbf
    U}{\partial \mathbf{u}}(\mathbf{u})
\end{equation}
which is one-to-one mapping to $\mathbf{u}(\mathbf{v})$ due to the convexity of $U$. We could then write the conservation equation as follow:
\begin{equation} \label{eq:EntopyConservationEquation}
    \frac{\partial}{\partial t}\left[\mathbf
    u(\mathbf
    v)\right] + \frac{\partial}{\partial x}\left[\mathbf
    g(\mathbf
    v)\right] = 0, \ \mathbf{g(v)} = \mathbf{f}(\mathbf{u}(\mathbf{
    v}))
\end{equation}
We discretize Equation \ref{eq:EntopyConservationEquation} and \ref{eq:EntrpyInequality} and have the following:
\begin{equation} \label{eq:EntropySystem}
    \begin{split}
        &\frac{d}{dt} \left[\mathbf{u}(\mathbf{v_v}(t))\right] = -\frac{1}{\Delta x}\left[\mathbf
        {g}_{\nu+1/2} - \mathbf{g}_{\nu-1/2}\right]\\
        &\frac{d}{dt} V(\mathbf{v_\nu}(t)) + \frac{1}{\Delta x}\left[G_{\nu + 1/2} - G_{\nu - 1/2}\right] \leq 0 \\
    \end{split}
\end{equation}
which are the conservation equation along with its respective entropy inequality. Our end goal is \textit{entropy conservative} schemes, in which only the eqiality hold in Equation \ref{eq:EntrpyInequality}. We multply the first equation of Equation \ref{eq:EntropySystem} by the entropy variable by $\mathbf{v}_\nu^T(t) = U_\mathbf{u}^T(\mathbf{u_\nu(t)})$, which we obtain the following:
\begin{equation}\label{eq:Convert1}
    \frac{d}{dt}V(\mathbf{v}_\nu(t)) = \frac{d}{dt} U(\mathbf{u}_\nu(t)) = -\frac{1}{\Delta x} \mathbf{v}_\nu^T \left[\mathbf{g}_{\nu + 1/2} - \mathbf{g}_{\nu - 1/2}\right]
\end{equation}
which we could subsitute into the entropy condition and have the following equality. The expression:
\begin{equation}\label{eq:Convert2}
    \mathbf{v}_\nu^T \left[\mathbf{g}_{\nu + 1/2} - \mathbf{g}_{\nu - 1/2} \right] = \mathbf{G}_{\nu + 1/2} - \mathbf{G}_{\nu - 1/2}
\end{equation}
is conservative if and only if:
\begin{equation}\label{eq:Tadmor'sEntropyCriteria}
    \Delta \mathbf{v}_{\nu + 1/2}^T \mathbf{g}_{\nu + 1/2} = \Psi_{\nu + 1} - \Psi_\nu, \ \Delta \mathbf{v}_{\nu + 1/2} = \mathbf{v_{\nu + 1}} - \mathbf{v}_\mathbf{\nu}
\end{equation}
This is Tadmor's entropy stability criterion. $\mathbf{g}_{\nu + 1/2}$ could be taken as any numerical flux, while for Euler's equation in 1D:
\begin{equation}
    \begin{split}
        \mathbf{v} &= 
        \begin{pmatrix}
            \frac{\gamma - S}{\gamma - 1}-\frac{\rho u^2}{2p} \\
            \frac{m}{p}\\
            -\frac{\rho}{p}
        \end{pmatrix}\\
        \Psi &= \rho u
    \end{split}
\end{equation} 
Tadmor's new criterion is different in that the amount of numerical viscosity present is essentially \textit{quanitified} and is then later used for Entropy stability evaluation. In addition, it is to be noted that Tadmor's criterion is extremely general, which means that it could be applied to any numerical flux. Any flux could be tested for its entropy conservation by directly substituting the relevant variables and fluxes into Equation \ref{eq:Tadmor'sEntropyCriteria}.


%---------------------------------------------------------------------------------
\subsection{Tadmor's Second Theorem}
In [], Tadmor only proved entropy conservation (i.e Entropy is equal across a cell interface), not stability. He later extended his idea to essentially three-point scheme and proved that: \textit{A conservative scheme which contains more numerical viscosity than that present in the entropy conservative one is entropy stable}. 

Essentially, we consider three points schemes that could be written in the following viscosity form:
\begin{equation} \label{eq:EntropyConservedScheme_Viscosity_form}
    \frac{d}{dt}\left[\mathbf(
    u(\mathbf{v_\nu}(t)))\right] = - \frac{1}{2\Delta x} \left[\mathbf
    {g}(\mathbf{v_{\nu+1}}) - \mathbf{g}(\mathbf{v_{\nu-1}})\right] + \frac{1}{2\Delta x} \left[Q_{\nu + 1/2} \Delta \mathbf{v}_{\nu+1/2} - Q_{\nu + 1/2} \Delta \mathbf{v}_{\mathbf{v}-1/2}\right]
\end{equation}
Where $Q_{\mathbf{v}+1/2}$ is referred to as the numerical viscosity coefficient matrix. We note that the class of three-point schemes includes second-prder accurate TVD schemes such as the High-Resolution Osher flux and a number of other schemes [][]. We then introduce a new variable:
\begin{equation}
    D_{\nu + 1/2} = Q_{\nu + 1/2} - Q_{\nu + 1/2}^*
\end{equation}
which denote the deviation of its viscosity from that of the entropy conservative scheme, which we then have:
\begin{equation}
    \frac{d}{dt}\left[\mathbf(
    u(\mathbf{v_\nu}(t)))\right] = - \frac{1}{2\Delta x} \left[\mathbf
    {g}(\mathbf{v_{\nu+1}}) - \mathbf{g}(\mathbf{v_{\nu-1}})\right] + \frac{1}{2\Delta x} \left[D_{\nu + 1/2} \Delta \mathbf{v}_{\nu+1/2} - D_{\nu + 1/2} \Delta \mathbf{v}_{\mathbf{v}-1/2}\right]
\end{equation}
We could also rewrite the above equation in the form of entropy condition (as per last section), following essentially the same step as outlined in Equation \ref{eq:Convert1} and Equation \ref{eq:Convert2} and use identities outlined in [] to obtain the following:
\begin{equation}
    \begin{split}
        \frac{d}{dt} V(\mathbf{v}_\nu(t)) + \frac{1}{\Delta x}\left[G_{\nu + 1/2} - G_{\nu - 1/2}\right] = -\frac{1}{4\Delta x} \left[\Delta \mathbf{v}_{\nu+1/2}^T D_{\nu + 1/2} \Delta \mathbf{v}_{\nu+1/2} - \Delta \mathbf{v}_{\nu-1/2}^T D_{\nu - 1/2} \Delta \mathbf{v}_{\nu-1/2}\right]
    \end{split}
\end{equation}
We observe that if the scheme is considered to contain more viscosity, then $D$ would be positive, and the overall right hand side of the above equation remains \textit{negative}, which then leads to the entropy condition being satisfied (Equation \ref{eq:EntropySystem}). This theorem allows us to tune additional numerical viscosity such that both entropy stability and second order accuracy could be obtained.

\section{Roe's Entropy Conservative Flux}
In 2006, building on top of Tadmor's theorems presented above, Roe made key contribution in Entropy stable fluxes [] by presenting an \textit{entropy conservative} flux that could be made \textit{stable} via upwinding. In this section, we summarize Roe's contribution and discuss his findings.

\subsection{Entropy Production}
From Tadmor, we know that entropy production across an interface could be characterized by the following equation:
\begin{equation}
    \Delta \mathbf{v}_{\nu + 1/2}^T \mathbf{g}_{\nu + 1/2} - (\Psi_{\nu + 1} - \Psi_\nu), \ \Delta \mathbf{v}_{\nu + 1/2} = \mathbf{v_{\nu + 1}} - \mathbf{v}_\mathbf{\nu}
\end{equation}
where $\mathbf{v}$ represents the entropy variable and $\Psi$ is an arbitary grid function. For Euler's equation in 1D, the above two quanitites are:
\begin{equation}
    \begin{split}
        \mathbf{v} &= 
        \begin{pmatrix}
            \frac{\gamma - S}{\gamma - 1}-\frac{\rho u^2}{2p} \\
            \frac{m}{p}\\
            -\frac{\rho}{p}
        \end{pmatrix}\\
        \Psi &= \rho u
    \end{split}
\end{equation} 
We use the following short hand $\left[\cdot \right]$ to represent the difference between two neighboring cells. We then have the following entropy production
\begin{equation}
    \left[\mathbf{v}\right] \cdot \mathbf{g} - \left[\Psi\right]
\end{equation}
It could be shown that if the flux is of central difference type $g = \bar{g}$, then the entropy production is of 3rd order:
\begin{equation}
    \left[\mathbf{v}\right] \cdot \bar{g} = \mathcal{O}(\delta^3)
\end{equation}
The third order production is small in smooth region, large across shocks and incorrect across rarefraction waves. The large production production across shocks are essentially correct since entropy across shocks should increase. However, it is incorrect across rarefractions as entropy production should be zero across rarefraction waves. We at first seek to construct an entropy conservative flux, which for Euler's equations, satisfy the following:
\begin{equation}
    \left[\mathbf{v}\right] \cdot \mathbf{g} = \left[\rho u\right]
\end{equation}
Roe then introduced the following Entropy conservative flux:
\subsection{An Entropy Conservative Flux}
We at first define a parameter vector:
\begin{equation}
    \mathbf{z} = \sqrt{\frac{\rho}{p}} (1, u, p)
\end{equation}
which we could then redefine the entropy variable as:
\begin{equation}
    \mathbf{v} = \left(\frac{\gamma}{\gamma - 1} + \frac{\gamma + 1}{\gamma -1} \ln z_1 + \ln z_3 - \frac{1}{2} z_2^2, z_1 z_2, -z_1^2\right)^T
\end{equation}
We then have the following flux:
\begin{equation}
    \begin{split}
        f_1^* &= \bar{z}_1 \bar{z}_3^{\ln}\\
        f_2^* &= \frac{\bar{z}_3 + \bar{z}_2 f_1^*}{\bar{z}_1}\\
        f_3^* &= \frac{1}{2\bar{z}_1}\left(\frac{\gamma + 1}{\gamma -1} \frac{f_1^*}{z_1^{\ln}} + \bar{z}_2 f_2^* \right)
    \end{split}
\end{equation}
This flux exactly preserves entropy across discontinuities. In addition, note that logarithmic mean, $(\cdot)^{\ln}$, is used here. 
logarithmic mean is defined as follow:
\begin{equation}
    L(x_1,x_2) = \frac{x_1 - x_2}{\ln x_1 - \ln x_2}
\end{equation}
We see that if $x_1$ and $x_2$ both approach $x$, then the entire expression would reduce to $x$. This average allows us to replace $\left[\ln p\right]$ with $\frac{\left[p\right]}{p^{\ln}}$ where $p^{\ln} = L(p_L,p_R)$.
Another reason why logarithmic mean maybe preferred more than arithmatic mean is their tendency to take a lower mean of when the pair of number givens are extremely far apart. Therefore this will act as an limiter that limits the flux states when encoutering disconnected values such as across a discontinuity. 

\subsection{Entropy Stability via Upwinding}
So far the flux presented exactly preserves entropy (i.e only the equality in Equation \ref{eq:EntrpyInequality} is satisfied). However, it is not really \textit{entropy stable}. We then proceed to consider upwinding. A typical first order upwind flux is written as follow:
\begin{equation} \label{eq:oldFlux}
    f^* = \bar{f} - \frac{1}{2}\left|\mathbf{A} \right| \left[\mathbf{u}\right]
\end{equation}
The second term introduces the upwind component on top of a central flux. $\left|\mathbf{A}\right| = \mathbf{R \left|\Lambda \right| L }$ is the absolute value of the flux Jacobian evaluated at an arbitary state (i.e Roe's averaged state). Following Tadmor's approach, we quanitify that the entropy produced at with the upwind is:
\begin{equation}
    -\frac{1}{2} \left[\mathbf{v}\right] \mathbf{R \left|\Lambda \right| L } \left[\mathbf{u}\right]
\end{equation}
For very strong shock the sign may become inconsisten, therefore Roe introduced a reformulation such that the right hand side will be in positive definite quadratic form[]:
\begin{equation}
    -\frac{1}{2} \left[\mathbf{v}\right] \mathbf{R \left|\Lambda \right| L } \left[\mathbf{u}\right] = \frac{1}{2}\left[\mathbf{v}\right] \mathbf{R \left|\Lambda \right| R^T } \left[\mathbf{v}\right]
\end{equation}
We then have the following new \textit{entropy stable} upwind flux:
\begin{equation} \label{eq:newFlux}
    f^*_{\text{new}} = f_C - \frac{1}{2} \mathbf{R \left|\Lambda \right| R^T } \left[\mathbf{v}\right]
\end{equation}
where $f_C$ denotes the entropy conservative flux introduced in the previous section. We note that the $f_C$ flux is already entropy conservative. Mathematically, it satisfies the Tadmor conservation criterion: 
\begin{equation}
    \left[\mathbf{v}\right]\cdot f_C = \left[\rho u\right]
\end{equation}
Then, the introduction of the upwinding with a \textit{constant} sign via reformulation guaranteed that the following \textit{inequality} will be satisfied:
\begin{equation}
    \left[\mathbf{v}\right] \cdot f^*_{\text{new}} \leq \left[\rho u\right]
\end{equation}
which satisfies the entropy condition, and that the new flux is entropy \textit{stable}. 

Roe mentions that the new flux cures two shock instability problems in 1D.
\begin{enumerate}
    \item For high mach number, the upwind scheme with un-reformulated upwind (Equation \ref{eq:oldFlux}) or Godunov's scheme will have spontaneously relocation of shocks
    \item The un-reformulated flux and Godunov scheme will sometimes gives rise to waves that reflect perpetually between the shock and the boundary
\end{enumerate}
With the new entropy stable flux, both problems are removed. However, Roe noted that the new flux experiences overshoots when predicting shocks. That is, the state values immediately beside a discontinuity are over-predicted. This is due to upwind component of Equation \ref{eq:newFlux} generates entropy at $\mathcal{O}(\delta^2)$, while the entropy generated by shock is $\mathcal{O}(\delta^3)$. 

Recall that the central flux generated $\mathcal{O}(\delta^3)$ flux in the old flux formulation Equation \ref{eq:oldFlux}. Roe then derived an additional flux term in Equation \ref{eq:oldFlux}:
\begin{equation}
    f^* = f_C - \frac{1}{2}\mathbf{R}(\left|\Lambda \right| + \alpha \left| \left[\Lambda\right] \right|) \mathbf{R}^T \left[\mathbf{v}\right]
\end{equation}
where we could take $\alpha \approx 1/3$ and the new scheme would elimniate overshoots.

In summary, building on top of Tadmor's entropy criterion, Roe was able to quantify the amount of entropy produced in a scheme and construct an entropy \textit{conservative} flux. He then introduced an upwind component with a constant sign that is guaranteed to satisfy the entropy condition, making the new scheme ultimately entropy \textit{stable}.

We consider \cite[text]{}
%---------------------------------------------------------------------------------------------
\bibliographystyle{plain} % We choose the "plain" reference style
\bibliography{refs} % Entries are in the refs.bib file

\end{document}